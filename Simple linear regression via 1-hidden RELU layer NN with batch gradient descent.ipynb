{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Cell 0 ###\n",
    "### Imports ###\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Cell 1 ###\n",
    "### Data generation and normalization ###\n",
    "\n",
    "train_size = 3000\n",
    "valid_size = 1000\n",
    "test_size = 1000\n",
    "\n",
    "# y = k * x + b\n",
    "k = 2\n",
    "b = 5\n",
    "\n",
    "# It is important to properly shuffle the training data -- failure to do so may result in SGD diverging.\n",
    "\n",
    "# From 0 to 10, uniformly distributed values.\n",
    "train_x = (10 * np.random.rand(train_size)).astype(np.float32).reshape((train_size, -1))\n",
    "train_y = (k * train_x + b + 0.01 * np.random.randn()).reshape((train_size, -1))\n",
    "valid_x = (10 * np.random.rand(valid_size)).astype(np.float32).reshape((valid_size, -1))\n",
    "valid_y = (k * valid_x + b + 0.01 * np.random.randn()).reshape((valid_size, -1))\n",
    "test_x = (10 * np.random.rand(test_size)).astype(np.float32).reshape((test_size, -1))\n",
    "test_y = (k * test_x + b + 0.01 * np.random.randn()).reshape((test_size, -1))\n",
    "\n",
    "# Rescale to [-1; 1]\n",
    "def normalize(arr):\n",
    "    return (arr - np.mean(arr)) / (np.max(arr) - np.min(arr))\n",
    "train_x = normalize(train_x)\n",
    "train_y = normalize(train_y)\n",
    "valid_x = normalize(valid_x)\n",
    "valid_y = normalize(valid_y)\n",
    "test_x = normalize(test_x)\n",
    "test_y = normalize(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Cell 2 ###\n",
    "### TensorFlow Graph definition ###\n",
    "\n",
    "batch_size = 300\n",
    "learning_rate = 0.00005\n",
    "hidden_layer_size = 64 # RELU layer.\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, train_x.shape[1]))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, train_y.shape[1]))\n",
    "    tf_valid_dataset = tf.constant(valid_x)\n",
    "    tf_test_dataset = tf.constant(test_x)\n",
    "    \n",
    "    # Hidden layer.\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([train_x.shape[1], hidden_layer_size]))\n",
    "    biases_1 = tf.Variable(tf.zeros([train_y.shape[1]]))\n",
    "    hidden = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "    \n",
    "    # Output layer.\n",
    "    weights_2 = tf.Variable(tf.truncated_normal([hidden_layer_size, train_y.shape[1]]))\n",
    "    biases_2 = tf.Variable(tf.zeros([train_y.shape[1]]))\n",
    "  \n",
    "    # Training step computation.\n",
    "    logits = tf.matmul(hidden, weights_2) + biases_2\n",
    "    loss = tf.nn.l2_loss(logits - tf_train_labels) / batch_size\n",
    "  \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    train_hidden = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "    train_prediction = tf.matmul(train_hidden, weights_2) + biases_2\n",
    "    \n",
    "    valid_hidden = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "    valid_prediction = tf.matmul(valid_hidden, weights_2) + biases_2\n",
    "    \n",
    "    test_hidden = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "    test_prediction = tf.matmul(test_hidden, weights_2) + biases_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss at step 0: 0.06820954\n",
      "Validation loss at step 0: 0.06943816\n",
      "\n",
      "Batch loss at step 20: 0.06817070\n",
      "Validation loss at step 20: 0.06892876\n",
      "\n",
      "Batch loss at step 40: 0.06810138\n",
      "Validation loss at step 40: 0.06842513\n",
      "\n",
      "Batch loss at step 60: 0.06739894\n",
      "Validation loss at step 60: 0.06792445\n",
      "\n",
      "Batch loss at step 80: 0.06507642\n",
      "Validation loss at step 80: 0.06742749\n",
      "\n",
      "Batch loss at step 100: 0.07037343\n",
      "Validation loss at step 100: 0.06693118\n",
      "\n",
      "Batch loss at step 120: 0.06330893\n",
      "Validation loss at step 120: 0.06644075\n",
      "\n",
      "Batch loss at step 140: 0.06220790\n",
      "Validation loss at step 140: 0.06595333\n",
      "\n",
      "Batch loss at step 160: 0.06212242\n",
      "Validation loss at step 160: 0.06546915\n",
      "\n",
      "Batch loss at step 180: 0.06378719\n",
      "Validation loss at step 180: 0.06498804\n",
      "\n",
      "Batch loss at step 200: 0.06378284\n",
      "Validation loss at step 200: 0.06450843\n",
      "\n",
      "Batch loss at step 220: 0.06371924\n",
      "Validation loss at step 220: 0.06403475\n",
      "\n",
      "Batch loss at step 240: 0.06306570\n",
      "Validation loss at step 240: 0.06356420\n",
      "\n",
      "Batch loss at step 260: 0.06086835\n",
      "Validation loss at step 260: 0.06309764\n",
      "\n",
      "Batch loss at step 280: 0.06585061\n",
      "Validation loss at step 280: 0.06263161\n",
      "\n",
      "Batch loss at step 300: 0.05925012\n",
      "Validation loss at step 300: 0.06217143\n",
      "\n",
      "Batch loss at step 320: 0.05813960\n",
      "Validation loss at step 320: 0.06171446\n",
      "\n",
      "Batch loss at step 340: 0.05807877\n",
      "Validation loss at step 340: 0.06126115\n",
      "\n",
      "Batch loss at step 360: 0.05963289\n",
      "Validation loss at step 360: 0.06081072\n",
      "\n",
      "Batch loss at step 380: 0.05966928\n",
      "Validation loss at step 380: 0.06036183\n",
      "\n",
      "Batch loss at step 400: 0.05961460\n",
      "Validation loss at step 400: 0.05991836\n",
      "\n",
      "Batch loss at step 420: 0.05900949\n",
      "Validation loss at step 420: 0.05947831\n",
      "\n",
      "Batch loss at step 440: 0.05693438\n",
      "Validation loss at step 440: 0.05904297\n",
      "\n",
      "Batch loss at step 460: 0.06161379\n",
      "Validation loss at step 460: 0.05860916\n",
      "\n",
      "Batch loss at step 480: 0.05545345\n",
      "Validation loss at step 480: 0.05818157\n",
      "\n",
      "Batch loss at step 500: 0.05434714\n",
      "Validation loss at step 500: 0.05775732\n",
      "\n",
      "Batch loss at step 520: 0.05432508\n",
      "Validation loss at step 520: 0.05733686\n",
      "\n",
      "Batch loss at step 540: 0.05576617\n",
      "Validation loss at step 540: 0.05692028\n",
      "\n",
      "Batch loss at step 560: 0.05585377\n",
      "Validation loss at step 560: 0.05650644\n",
      "\n",
      "Batch loss at step 580: 0.05580238\n",
      "Validation loss at step 580: 0.05609863\n",
      "\n",
      "Batch loss at step 600: 0.05525303\n",
      "Validation loss at step 600: 0.05569464\n",
      "\n",
      "Batch loss at step 620: 0.05329705\n",
      "Validation loss at step 620: 0.05529493\n",
      "\n",
      "Batch loss at step 640: 0.05770430\n",
      "Validation loss at step 640: 0.05489664\n",
      "\n",
      "Batch loss at step 660: 0.05197120\n",
      "Validation loss at step 660: 0.05450429\n",
      "\n",
      "Batch loss at step 680: 0.05085848\n",
      "Validation loss at step 680: 0.05411553\n",
      "\n",
      "Batch loss at step 700: 0.05088063\n",
      "Validation loss at step 700: 0.05373080\n",
      "\n",
      "Batch loss at step 720: 0.05222154\n",
      "Validation loss at step 720: 0.05334947\n",
      "\n",
      "Batch loss at step 740: 0.05234255\n",
      "Validation loss at step 740: 0.05297008\n",
      "\n",
      "Batch loss at step 760: 0.05229200\n",
      "Validation loss at step 760: 0.05259598\n",
      "\n",
      "Batch loss at step 780: 0.05179476\n",
      "Validation loss at step 780: 0.05222537\n",
      "\n",
      "Batch loss at step 800: 0.04996104\n",
      "Validation loss at step 800: 0.05185931\n",
      "\n",
      "Batch loss at step 820: 0.05411979\n",
      "Validation loss at step 820: 0.05149490\n",
      "\n",
      "Batch loss at step 840: 0.04877720\n",
      "Validation loss at step 840: 0.05113593\n",
      "\n",
      "Batch loss at step 860: 0.04765986\n",
      "Validation loss at step 860: 0.05078021\n",
      "\n",
      "Batch loss at step 880: 0.04772327\n",
      "Validation loss at step 880: 0.05042783\n",
      "\n",
      "Batch loss at step 900: 0.04897769\n",
      "Validation loss at step 900: 0.05007905\n",
      "\n",
      "Batch loss at step 920: 0.04911624\n",
      "Validation loss at step 920: 0.04973193\n",
      "\n",
      "Batch loss at step 940: 0.04907684\n",
      "Validation loss at step 940: 0.04939056\n",
      "\n",
      "Batch loss at step 960: 0.04863390\n",
      "Validation loss at step 960: 0.04905262\n",
      "\n",
      "Batch loss at step 980: 0.04692535\n",
      "Validation loss at step 980: 0.04871855\n",
      "\n",
      "Batch loss at step 1000: 0.05083913\n",
      "Validation loss at step 1000: 0.04838566\n",
      "\n",
      "Batch loss at step 1020: 0.04586383\n",
      "Validation loss at step 1020: 0.04805739\n",
      "\n",
      "Batch loss at step 1040: 0.04474953\n",
      "Validation loss at step 1040: 0.04773176\n",
      "\n",
      "Batch loss at step 1060: 0.04483950\n",
      "Validation loss at step 1060: 0.04740907\n",
      "\n",
      "Batch loss at step 1080: 0.04602496\n",
      "Validation loss at step 1080: 0.04708916\n",
      "\n",
      "Batch loss at step 1100: 0.04616037\n",
      "Validation loss at step 1100: 0.04677072\n",
      "\n",
      "Batch loss at step 1120: 0.04612734\n",
      "Validation loss at step 1120: 0.04645656\n",
      "\n",
      "Batch loss at step 1140: 0.04574522\n",
      "Validation loss at step 1140: 0.04614554\n",
      "\n",
      "Batch loss at step 1160: 0.04414729\n",
      "Validation loss at step 1160: 0.04583771\n",
      "\n",
      "Batch loss at step 1180: 0.04783892\n",
      "Validation loss at step 1180: 0.04553067\n",
      "\n",
      "Batch loss at step 1200: 0.04319622\n",
      "Validation loss at step 1200: 0.04522786\n",
      "\n",
      "Batch loss at step 1220: 0.04209406\n",
      "Validation loss at step 1220: 0.04492793\n",
      "\n",
      "Batch loss at step 1240: 0.04219028\n",
      "Validation loss at step 1240: 0.04463019\n",
      "\n",
      "Batch loss at step 1260: 0.04331453\n",
      "Validation loss at step 1260: 0.04433537\n",
      "\n",
      "Batch loss at step 1280: 0.04344439\n",
      "Validation loss at step 1280: 0.04404147\n",
      "\n",
      "Batch loss at step 1300: 0.04342384\n",
      "Validation loss at step 1300: 0.04375170\n",
      "\n",
      "Batch loss at step 1320: 0.04307350\n",
      "Validation loss at step 1320: 0.04346453\n",
      "\n",
      "Batch loss at step 1340: 0.04158185\n",
      "Validation loss at step 1340: 0.04318044\n",
      "\n",
      "Batch loss at step 1360: 0.04506519\n",
      "Validation loss at step 1360: 0.04289703\n",
      "\n",
      "Batch loss at step 1380: 0.04073835\n",
      "Validation loss at step 1380: 0.04261784\n",
      "\n",
      "Batch loss at step 1400: 0.03965095\n",
      "Validation loss at step 1400: 0.04234082\n",
      "\n",
      "Batch loss at step 1420: 0.03974650\n",
      "Validation loss at step 1420: 0.04206588\n",
      "\n",
      "Batch loss at step 1440: 0.04080598\n",
      "Validation loss at step 1440: 0.04179318\n",
      "\n",
      "Batch loss at step 1460: 0.04094990\n",
      "Validation loss at step 1460: 0.04152155\n",
      "\n",
      "Batch loss at step 1480: 0.04093040\n",
      "Validation loss at step 1480: 0.04125337\n",
      "\n",
      "Batch loss at step 1500: 0.04059725\n",
      "Validation loss at step 1500: 0.04098738\n",
      "\n",
      "Batch loss at step 1520: 0.03920973\n",
      "Validation loss at step 1520: 0.04072395\n",
      "\n",
      "Batch loss at step 1540: 0.04249386\n",
      "Validation loss at step 1540: 0.04046099\n",
      "\n",
      "Batch loss at step 1560: 0.03845618\n",
      "Validation loss at step 1560: 0.04020152\n",
      "\n",
      "Batch loss at step 1580: 0.03738399\n",
      "Validation loss at step 1580: 0.03994430\n",
      "\n",
      "Batch loss at step 1600: 0.03747022\n",
      "Validation loss at step 1600: 0.03968913\n",
      "\n",
      "Batch loss at step 1620: 0.03848422\n",
      "Validation loss at step 1620: 0.03943618\n",
      "\n",
      "Batch loss at step 1640: 0.03863008\n",
      "Validation loss at step 1640: 0.03918399\n",
      "\n",
      "Batch loss at step 1660: 0.03862785\n",
      "Validation loss at step 1660: 0.03893539\n",
      "\n",
      "Batch loss at step 1680: 0.03830559\n",
      "Validation loss at step 1680: 0.03868864\n",
      "\n",
      "Batch loss at step 1700: 0.03701267\n",
      "Validation loss at step 1700: 0.03844386\n",
      "\n",
      "Batch loss at step 1720: 0.04012137\n",
      "Validation loss at step 1720: 0.03819970\n",
      "\n",
      "Batch loss at step 1740: 0.03634061\n",
      "Validation loss at step 1740: 0.03795880\n",
      "\n",
      "Batch loss at step 1760: 0.03529126\n",
      "Validation loss at step 1760: 0.03771955\n",
      "\n",
      "Batch loss at step 1780: 0.03535704\n",
      "Validation loss at step 1780: 0.03748174\n",
      "\n",
      "Batch loss at step 1800: 0.03634662\n",
      "Validation loss at step 1800: 0.03724610\n",
      "\n",
      "Batch loss at step 1820: 0.03647553\n",
      "Validation loss at step 1820: 0.03701100\n",
      "\n",
      "Batch loss at step 1840: 0.03649531\n",
      "Validation loss at step 1840: 0.03677868\n",
      "\n",
      "Batch loss at step 1860: 0.03618461\n",
      "Validation loss at step 1860: 0.03654797\n",
      "\n",
      "Batch loss at step 1880: 0.03496927\n",
      "Validation loss at step 1880: 0.03631908\n",
      "\n",
      "Batch loss at step 1900: 0.03791201\n",
      "Validation loss at step 1900: 0.03609055\n",
      "\n",
      "Batch loss at step 1920: 0.03436302\n",
      "Validation loss at step 1920: 0.03586441\n",
      "\n",
      "Batch loss at step 1940: 0.03333510\n",
      "Validation loss at step 1940: 0.03563975\n",
      "\n",
      "Batch loss at step 1960: 0.03338045\n",
      "Validation loss at step 1960: 0.03541646\n",
      "\n",
      "Batch loss at step 1980: 0.03434709\n",
      "Validation loss at step 1980: 0.03519513\n",
      "\n",
      "Batch loss at step 2000: 0.03445980\n",
      "Validation loss at step 2000: 0.03497422\n",
      "\n",
      "Batch loss at step 2020: 0.03449007\n",
      "Validation loss at step 2020: 0.03475610\n",
      "\n",
      "Batch loss at step 2040: 0.03419906\n",
      "Validation loss at step 2040: 0.03454001\n",
      "\n",
      "Batch loss at step 2060: 0.03305651\n",
      "Validation loss at step 2060: 0.03432560\n",
      "\n",
      "Batch loss at step 2080: 0.03584038\n",
      "Validation loss at step 2080: 0.03411138\n",
      "\n",
      "Batch loss at step 2100: 0.03249733\n",
      "Validation loss at step 2100: 0.03389942\n",
      "\n",
      "Batch loss at step 2120: 0.03150139\n",
      "Validation loss at step 2120: 0.03368885\n",
      "\n",
      "Batch loss at step 2140: 0.03153544\n",
      "Validation loss at step 2140: 0.03347972\n",
      "\n",
      "Batch loss at step 2160: 0.03246842\n",
      "Validation loss at step 2160: 0.03327212\n",
      "\n",
      "Batch loss at step 2180: 0.03256680\n",
      "Validation loss at step 2180: 0.03306488\n",
      "\n",
      "Batch loss at step 2200: 0.03260902\n",
      "Validation loss at step 2200: 0.03286001\n",
      "\n",
      "Batch loss at step 2220: 0.03233719\n",
      "Validation loss at step 2220: 0.03265686\n",
      "\n",
      "Batch loss at step 2240: 0.03126091\n",
      "Validation loss at step 2240: 0.03245509\n",
      "\n",
      "Batch loss at step 2260: 0.03389314\n",
      "Validation loss at step 2260: 0.03225347\n",
      "\n",
      "Batch loss at step 2280: 0.03073445\n",
      "Validation loss at step 2280: 0.03205409\n",
      "\n",
      "Batch loss at step 2300: 0.02978580\n",
      "Validation loss at step 2300: 0.03185628\n",
      "\n",
      "Batch loss at step 2320: 0.02980204\n",
      "Validation loss at step 2320: 0.03165965\n",
      "\n",
      "Batch loss at step 2340: 0.03069188\n",
      "Validation loss at step 2340: 0.03146440\n",
      "\n",
      "Batch loss at step 2360: 0.03078913\n",
      "Validation loss at step 2360: 0.03126959\n",
      "\n",
      "Batch loss at step 2380: 0.03083741\n",
      "Validation loss at step 2380: 0.03107721\n",
      "\n",
      "Batch loss at step 2400: 0.03059171\n",
      "Validation loss at step 2400: 0.03088641\n",
      "\n",
      "Batch loss at step 2420: 0.02957452\n",
      "Validation loss at step 2420: 0.03069703\n",
      "\n",
      "Batch loss at step 2440: 0.03206031\n",
      "Validation loss at step 2440: 0.03050763\n",
      "\n",
      "Batch loss at step 2460: 0.02907448\n",
      "Validation loss at step 2460: 0.03032030\n",
      "\n",
      "Batch loss at step 2480: 0.02817420\n",
      "Validation loss at step 2480: 0.03013440\n",
      "\n",
      "Batch loss at step 2500: 0.02816870\n",
      "Validation loss at step 2500: 0.02994960\n",
      "\n",
      "Batch loss at step 2520: 0.02902606\n",
      "Validation loss at step 2520: 0.02976614\n",
      "\n",
      "Batch loss at step 2540: 0.02912188\n",
      "Validation loss at step 2540: 0.02958289\n",
      "\n",
      "Batch loss at step 2560: 0.02917537\n",
      "Validation loss at step 2560: 0.02940184\n",
      "\n",
      "Batch loss at step 2580: 0.02895424\n",
      "Validation loss at step 2580: 0.02922214\n",
      "\n",
      "Batch loss at step 2600: 0.02798788\n",
      "Validation loss at step 2600: 0.02904361\n",
      "\n",
      "Batch loss at step 2620: 0.03032752\n",
      "Validation loss at step 2620: 0.02886495\n",
      "\n",
      "Batch loss at step 2640: 0.02751092\n",
      "Validation loss at step 2640: 0.02868829\n",
      "\n",
      "Batch loss at step 2660: 0.02665571\n",
      "Validation loss at step 2660: 0.02851308\n",
      "\n",
      "Batch loss at step 2680: 0.02663874\n",
      "Validation loss at step 2680: 0.02833902\n",
      "\n",
      "Batch loss at step 2700: 0.02746362\n",
      "Validation loss at step 2700: 0.02816605\n",
      "\n",
      "Batch loss at step 2720: 0.02755529\n",
      "Validation loss at step 2720: 0.02799332\n",
      "\n",
      "Batch loss at step 2740: 0.02761243\n",
      "Validation loss at step 2740: 0.02782254\n",
      "\n",
      "Batch loss at step 2760: 0.02741388\n",
      "Validation loss at step 2760: 0.02765314\n",
      "\n",
      "Batch loss at step 2780: 0.02648884\n",
      "Validation loss at step 2780: 0.02748494\n",
      "\n",
      "Batch loss at step 2800: 0.02869287\n",
      "Validation loss at step 2800: 0.02731686\n",
      "\n",
      "Batch loss at step 2820: 0.02603667\n",
      "Validation loss at step 2820: 0.02715077\n",
      "\n",
      "Batch loss at step 2840: 0.02522190\n",
      "Validation loss at step 2840: 0.02698583\n",
      "\n",
      "Batch loss at step 2860: 0.02520014\n",
      "Validation loss at step 2860: 0.02682196\n",
      "\n",
      "Batch loss at step 2880: 0.02599180\n",
      "Validation loss at step 2880: 0.02665908\n",
      "\n",
      "Batch loss at step 2900: 0.02607607\n",
      "Validation loss at step 2900: 0.02649635\n",
      "\n",
      "Batch loss at step 2920: 0.02613664\n",
      "Validation loss at step 2920: 0.02633549\n",
      "\n",
      "Batch loss at step 2940: 0.02595926\n",
      "Validation loss at step 2940: 0.02617588\n",
      "\n",
      "Batch loss at step 2960: 0.02507762\n",
      "Validation loss at step 2960: 0.02601743\n",
      "\n",
      "Batch loss at step 2980: 0.02715174\n",
      "Validation loss at step 2980: 0.02585905\n",
      "\n",
      "Batch loss at step 3000: 0.02464429\n",
      "Validation loss at step 3000: 0.02570231\n",
      "\n",
      "Batch loss at step 3020: 0.02387020\n",
      "Validation loss at step 3020: 0.02554666\n",
      "\n",
      "Batch loss at step 3040: 0.02384005\n",
      "Validation loss at step 3040: 0.02539188\n",
      "\n",
      "Batch loss at step 3060: 0.02460690\n",
      "Validation loss at step 3060: 0.02523806\n",
      "\n",
      "Batch loss at step 3080: 0.02467698\n",
      "Validation loss at step 3080: 0.02508424\n",
      "\n",
      "Batch loss at step 3100: 0.02474404\n",
      "Validation loss at step 3100: 0.02493213\n",
      "\n",
      "Batch loss at step 3120: 0.02458441\n",
      "Validation loss at step 3120: 0.02478126\n",
      "\n",
      "Batch loss at step 3140: 0.02374501\n",
      "Validation loss at step 3140: 0.02463146\n",
      "\n",
      "Batch loss at step 3160: 0.02569572\n",
      "Validation loss at step 3160: 0.02448155\n",
      "\n",
      "Batch loss at step 3180: 0.02333166\n",
      "Validation loss at step 3180: 0.02433325\n",
      "\n",
      "Batch loss at step 3200: 0.02259265\n",
      "Validation loss at step 3200: 0.02418602\n",
      "\n",
      "Batch loss at step 3220: 0.02255900\n",
      "Validation loss at step 3220: 0.02403952\n",
      "\n",
      "Batch loss at step 3240: 0.02329953\n",
      "Validation loss at step 3240: 0.02389396\n",
      "\n",
      "Batch loss at step 3260: 0.02335660\n",
      "Validation loss at step 3260: 0.02374843\n",
      "\n",
      "Batch loss at step 3280: 0.02343184\n",
      "Validation loss at step 3280: 0.02360461\n",
      "\n",
      "Batch loss at step 3300: 0.02328661\n",
      "Validation loss at step 3300: 0.02346184\n",
      "\n",
      "Batch loss at step 3320: 0.02248221\n",
      "Validation loss at step 3320: 0.02332020\n",
      "\n",
      "Batch loss at step 3340: 0.02431851\n",
      "Validation loss at step 3340: 0.02317877\n",
      "\n",
      "Batch loss at step 3360: 0.02210001\n",
      "Validation loss at step 3360: 0.02303881\n",
      "\n",
      "Batch loss at step 3380: 0.02138640\n",
      "Validation loss at step 3380: 0.02289961\n",
      "\n",
      "Batch loss at step 3400: 0.02134956\n",
      "Validation loss at step 3400: 0.02276122\n",
      "\n",
      "Batch loss at step 3420: 0.02206310\n",
      "Validation loss at step 3420: 0.02262381\n",
      "\n",
      "Batch loss at step 3440: 0.02211012\n",
      "Validation loss at step 3440: 0.02248645\n",
      "\n",
      "Batch loss at step 3460: 0.02219002\n",
      "Validation loss at step 3460: 0.02235073\n",
      "\n",
      "Batch loss at step 3480: 0.02205665\n",
      "Validation loss at step 3480: 0.02221584\n",
      "\n",
      "Batch loss at step 3500: 0.02128637\n",
      "Validation loss at step 3500: 0.02208201\n",
      "\n",
      "Batch loss at step 3520: 0.02302024\n",
      "Validation loss at step 3520: 0.02194823\n",
      "\n",
      "Batch loss at step 3540: 0.02093884\n",
      "Validation loss at step 3540: 0.02181597\n",
      "\n",
      "Batch loss at step 3560: 0.02024699\n",
      "Validation loss at step 3560: 0.02168472\n",
      "\n",
      "Batch loss at step 3580: 0.02020930\n",
      "Validation loss at step 3580: 0.02155428\n",
      "\n",
      "Batch loss at step 3600: 0.02089418\n",
      "Validation loss at step 3600: 0.02142453\n",
      "\n",
      "Batch loss at step 3620: 0.02093393\n",
      "Validation loss at step 3620: 0.02129493\n",
      "\n",
      "Batch loss at step 3640: 0.02101954\n",
      "Validation loss at step 3640: 0.02116689\n",
      "\n",
      "Batch loss at step 3660: 0.02089251\n",
      "Validation loss at step 3660: 0.02103970\n",
      "\n",
      "Batch loss at step 3680: 0.02015922\n",
      "Validation loss at step 3680: 0.02091330\n",
      "\n",
      "Batch loss at step 3700: 0.02179562\n",
      "Validation loss at step 3700: 0.02078698\n",
      "\n",
      "Batch loss at step 3720: 0.01984442\n",
      "Validation loss at step 3720: 0.02066207\n",
      "\n",
      "Batch loss at step 3740: 0.01917070\n",
      "Validation loss at step 3740: 0.02053799\n",
      "\n",
      "Batch loss at step 3760: 0.01913404\n",
      "Validation loss at step 3760: 0.02041469\n",
      "\n",
      "Batch loss at step 3780: 0.01978989\n",
      "Validation loss at step 3780: 0.02029215\n",
      "\n",
      "Batch loss at step 3800: 0.01982544\n",
      "Validation loss at step 3800: 0.02016969\n",
      "\n",
      "Batch loss at step 3820: 0.01991468\n",
      "Validation loss at step 3820: 0.02004856\n",
      "\n",
      "Batch loss at step 3840: 0.01979412\n",
      "Validation loss at step 3840: 0.01992829\n",
      "\n",
      "Batch loss at step 3860: 0.01909505\n",
      "Validation loss at step 3860: 0.01980894\n",
      "\n",
      "Batch loss at step 3880: 0.02064044\n",
      "Validation loss at step 3880: 0.01968961\n",
      "\n",
      "Batch loss at step 3900: 0.01880942\n",
      "Validation loss at step 3900: 0.01957155\n",
      "\n",
      "Batch loss at step 3920: 0.01815197\n",
      "Validation loss at step 3920: 0.01945421\n",
      "\n",
      "Batch loss at step 3940: 0.01811779\n",
      "Validation loss at step 3940: 0.01933751\n",
      "\n",
      "Batch loss at step 3960: 0.01874654\n",
      "Validation loss at step 3960: 0.01922151\n",
      "\n",
      "Batch loss at step 3980: 0.01877897\n",
      "Validation loss at step 3980: 0.01910569\n",
      "\n",
      "Batch loss at step 4000: 0.01886929\n",
      "Validation loss at step 4000: 0.01899115\n",
      "\n",
      "Batch loss at step 4020: 0.01875320\n",
      "Validation loss at step 4020: 0.01887739\n",
      "\n",
      "Batch loss at step 4040: 0.01808699\n",
      "Validation loss at step 4040: 0.01876448\n",
      "\n",
      "Batch loss at step 4060: 0.01954690\n",
      "Validation loss at step 4060: 0.01865168\n",
      "\n",
      "Batch loss at step 4080: 0.01782808\n",
      "Validation loss at step 4080: 0.01854020\n",
      "\n",
      "Batch loss at step 4100: 0.01718797\n",
      "Validation loss at step 4100: 0.01842940\n",
      "\n",
      "Batch loss at step 4120: 0.01715442\n",
      "Validation loss at step 4120: 0.01831926\n",
      "\n",
      "Batch loss at step 4140: 0.01775778\n",
      "Validation loss at step 4140: 0.01820975\n",
      "\n",
      "Batch loss at step 4160: 0.01779040\n",
      "Validation loss at step 4160: 0.01810031\n",
      "\n",
      "Batch loss at step 4180: 0.01788051\n",
      "Validation loss at step 4180: 0.01799214\n",
      "\n",
      "Batch loss at step 4200: 0.01776785\n",
      "Validation loss at step 4200: 0.01788469\n",
      "\n",
      "Batch loss at step 4220: 0.01713330\n",
      "Validation loss at step 4220: 0.01777803\n",
      "\n",
      "Batch loss at step 4240: 0.01851277\n",
      "Validation loss at step 4240: 0.01767134\n",
      "\n",
      "Batch loss at step 4260: 0.01690094\n",
      "Validation loss at step 4260: 0.01756594\n",
      "\n",
      "Batch loss at step 4280: 0.01627426\n",
      "Validation loss at step 4280: 0.01746116\n",
      "\n",
      "Batch loss at step 4300: 0.01624407\n",
      "Validation loss at step 4300: 0.01735704\n",
      "\n",
      "Batch loss at step 4320: 0.01681989\n",
      "Validation loss at step 4320: 0.01725351\n",
      "\n",
      "Batch loss at step 4340: 0.01685829\n",
      "Validation loss at step 4340: 0.01715009\n",
      "\n",
      "Batch loss at step 4360: 0.01694385\n",
      "Validation loss at step 4360: 0.01704780\n",
      "\n",
      "Batch loss at step 4380: 0.01683649\n",
      "Validation loss at step 4380: 0.01694615\n",
      "\n",
      "Batch loss at step 4400: 0.01623050\n",
      "Validation loss at step 4400: 0.01684524\n",
      "\n",
      "Batch loss at step 4420: 0.01753706\n",
      "Validation loss at step 4420: 0.01674429\n",
      "\n",
      "Batch loss at step 4440: 0.01602435\n",
      "Validation loss at step 4440: 0.01664446\n",
      "\n",
      "Batch loss at step 4460: 0.01541022\n",
      "Validation loss at step 4460: 0.01654527\n",
      "\n",
      "Batch loss at step 4480: 0.01538269\n",
      "Validation loss at step 4480: 0.01644663\n",
      "\n",
      "Batch loss at step 4500: 0.01593129\n",
      "Validation loss at step 4500: 0.01634859\n",
      "\n",
      "Batch loss at step 4520: 0.01597572\n",
      "Validation loss at step 4520: 0.01625067\n",
      "\n",
      "Batch loss at step 4540: 0.01605560\n",
      "Validation loss at step 4540: 0.01615389\n",
      "\n",
      "Batch loss at step 4560: 0.01595377\n",
      "Validation loss at step 4560: 0.01605765\n",
      "\n",
      "Batch loss at step 4580: 0.01537548\n",
      "Validation loss at step 4580: 0.01596211\n",
      "\n",
      "Batch loss at step 4600: 0.01661364\n",
      "Validation loss at step 4600: 0.01586655\n",
      "\n",
      "Batch loss at step 4620: 0.01519397\n",
      "Validation loss at step 4620: 0.01577211\n",
      "\n",
      "Batch loss at step 4640: 0.01459141\n",
      "Validation loss at step 4640: 0.01567814\n",
      "\n",
      "Batch loss at step 4660: 0.01456895\n",
      "Validation loss at step 4660: 0.01558475\n",
      "\n",
      "Batch loss at step 4680: 0.01508949\n",
      "Validation loss at step 4680: 0.01549190\n",
      "\n",
      "Batch loss at step 4700: 0.01514006\n",
      "Validation loss at step 4700: 0.01539921\n",
      "\n",
      "Batch loss at step 4720: 0.01521404\n",
      "Validation loss at step 4720: 0.01530750\n",
      "\n",
      "Batch loss at step 4740: 0.01511609\n",
      "Validation loss at step 4740: 0.01521643\n",
      "\n",
      "Batch loss at step 4760: 0.01456701\n",
      "Validation loss at step 4760: 0.01512600\n",
      "\n",
      "Batch loss at step 4780: 0.01573880\n",
      "Validation loss at step 4780: 0.01503566\n",
      "\n",
      "Batch loss at step 4800: 0.01440672\n",
      "Validation loss at step 4800: 0.01494631\n",
      "\n",
      "Batch loss at step 4820: 0.01381581\n",
      "Validation loss at step 4820: 0.01485755\n",
      "\n",
      "Batch loss at step 4840: 0.01379894\n",
      "Validation loss at step 4840: 0.01476929\n",
      "\n",
      "Batch loss at step 4860: 0.01429202\n",
      "Validation loss at step 4860: 0.01468150\n",
      "\n",
      "Batch loss at step 4880: 0.01434823\n",
      "Validation loss at step 4880: 0.01459383\n",
      "\n",
      "Batch loss at step 4900: 0.01441928\n",
      "Validation loss at step 4900: 0.01450713\n",
      "\n",
      "Batch loss at step 4920: 0.01432387\n",
      "Validation loss at step 4920: 0.01442093\n",
      "\n",
      "Batch loss at step 4940: 0.01380157\n",
      "Validation loss at step 4940: 0.01433534\n",
      "\n",
      "Batch loss at step 4960: 0.01491175\n",
      "Validation loss at step 4960: 0.01424968\n",
      "\n",
      "Batch loss at step 4980: 0.01366099\n",
      "Validation loss at step 4980: 0.01416498\n",
      "\n",
      "Batch loss at step 5000: 0.01307985\n",
      "Validation loss at step 5000: 0.01408076\n",
      "\n",
      "Batch loss at step 5020: 0.01306889\n",
      "Validation loss at step 5020: 0.01399706\n",
      "\n",
      "Batch loss at step 5040: 0.01353643\n",
      "Validation loss at step 5040: 0.01391380\n",
      "\n",
      "Batch loss at step 5060: 0.01359677\n",
      "Validation loss at step 5060: 0.01383065\n",
      "\n",
      "Batch loss at step 5080: 0.01366444\n",
      "Validation loss at step 5080: 0.01374837\n",
      "\n",
      "Batch loss at step 5100: 0.01357286\n",
      "Validation loss at step 5100: 0.01366664\n",
      "\n",
      "Batch loss at step 5120: 0.01307448\n",
      "Validation loss at step 5120: 0.01358543\n",
      "\n",
      "Batch loss at step 5140: 0.01412716\n",
      "Validation loss at step 5140: 0.01350421\n",
      "\n",
      "Batch loss at step 5160: 0.01295325\n",
      "Validation loss at step 5160: 0.01342378\n",
      "\n",
      "Batch loss at step 5180: 0.01238123\n",
      "Validation loss at step 5180: 0.01334386\n",
      "\n",
      "Batch loss at step 5200: 0.01237574\n",
      "Validation loss at step 5200: 0.01326441\n",
      "\n",
      "Batch loss at step 5220: 0.01281836\n",
      "Validation loss at step 5220: 0.01318539\n",
      "\n",
      "Batch loss at step 5240: 0.01288342\n",
      "Validation loss at step 5240: 0.01310645\n",
      "\n",
      "Batch loss at step 5260: 0.01294796\n",
      "Validation loss at step 5260: 0.01302828\n",
      "\n",
      "Batch loss at step 5280: 0.01286039\n",
      "Validation loss at step 5280: 0.01295065\n",
      "\n",
      "Batch loss at step 5300: 0.01238437\n",
      "Validation loss at step 5300: 0.01287360\n",
      "\n",
      "Batch loss at step 5320: 0.01338271\n",
      "Validation loss at step 5320: 0.01279652\n",
      "\n",
      "Batch loss at step 5340: 0.01228084\n",
      "Validation loss at step 5340: 0.01272028\n",
      "\n",
      "Batch loss at step 5360: 0.01171993\n",
      "Validation loss at step 5360: 0.01264452\n",
      "\n",
      "Batch loss at step 5380: 0.01171827\n",
      "Validation loss at step 5380: 0.01256919\n",
      "\n",
      "Batch loss at step 5400: 0.01213635\n",
      "Validation loss at step 5400: 0.01249426\n",
      "\n",
      "Batch loss at step 5420: 0.01220656\n",
      "Validation loss at step 5420: 0.01241946\n",
      "\n",
      "Batch loss at step 5440: 0.01226900\n",
      "Validation loss at step 5440: 0.01234541\n",
      "\n",
      "Batch loss at step 5460: 0.01218489\n",
      "Validation loss at step 5460: 0.01227183\n",
      "\n",
      "Batch loss at step 5480: 0.01172902\n",
      "Validation loss at step 5480: 0.01219876\n",
      "\n",
      "Batch loss at step 5500: 0.01267798\n",
      "Validation loss at step 5500: 0.01212571\n",
      "\n",
      "Batch loss at step 5520: 0.01164302\n",
      "Validation loss at step 5520: 0.01205347\n",
      "\n",
      "Batch loss at step 5540: 0.01109324\n",
      "Validation loss at step 5540: 0.01198168\n",
      "\n",
      "Batch loss at step 5560: 0.01109463\n",
      "Validation loss at step 5560: 0.01191027\n",
      "\n",
      "Batch loss at step 5580: 0.01149007\n",
      "Validation loss at step 5580: 0.01183924\n",
      "\n",
      "Batch loss at step 5600: 0.01156461\n",
      "Validation loss at step 5600: 0.01176830\n",
      "\n",
      "Batch loss at step 5620: 0.01162451\n",
      "Validation loss at step 5620: 0.01169809\n",
      "\n",
      "Batch loss at step 5640: 0.01154428\n",
      "Validation loss at step 5640: 0.01162836\n",
      "\n",
      "Batch loss at step 5660: 0.01110834\n",
      "Validation loss at step 5660: 0.01155918\n",
      "\n",
      "Batch loss at step 5680: 0.01201050\n",
      "Validation loss at step 5680: 0.01148995\n",
      "\n",
      "Batch loss at step 5700: 0.01103828\n",
      "Validation loss at step 5700: 0.01142143\n",
      "\n",
      "Batch loss at step 5720: 0.01049966\n",
      "Validation loss at step 5720: 0.01135336\n",
      "\n",
      "Batch loss at step 5740: 0.01050345\n",
      "Validation loss at step 5740: 0.01128563\n",
      "\n",
      "Batch loss at step 5760: 0.01087833\n",
      "Validation loss at step 5760: 0.01121828\n",
      "\n",
      "Batch loss at step 5780: 0.01095580\n",
      "Validation loss at step 5780: 0.01115099\n",
      "\n",
      "Batch loss at step 5800: 0.01101343\n",
      "Validation loss at step 5800: 0.01108443\n",
      "\n",
      "Batch loss at step 5820: 0.01093795\n",
      "Validation loss at step 5820: 0.01101832\n",
      "\n",
      "Batch loss at step 5840: 0.01052162\n",
      "Validation loss at step 5840: 0.01095269\n",
      "\n",
      "Batch loss at step 5860: 0.01137885\n",
      "Validation loss at step 5860: 0.01088710\n",
      "\n",
      "Batch loss at step 5880: 0.01046480\n",
      "Validation loss at step 5880: 0.01082219\n",
      "\n",
      "Batch loss at step 5900: 0.00993882\n",
      "Validation loss at step 5900: 0.01075772\n",
      "\n",
      "Batch loss at step 5920: 0.00994432\n",
      "Validation loss at step 5920: 0.01069359\n",
      "\n",
      "Batch loss at step 5940: 0.01029982\n",
      "Validation loss at step 5940: 0.01062983\n",
      "\n",
      "Batch loss at step 5960: 0.01037861\n",
      "Validation loss at step 5960: 0.01056618\n",
      "\n",
      "Batch loss at step 5980: 0.01043428\n",
      "Validation loss at step 5980: 0.01050319\n",
      "\n",
      "Batch loss at step 6000: 0.01036273\n",
      "Validation loss at step 6000: 0.01044058\n",
      "\n",
      "Batch loss at step 6020: 0.00996561\n",
      "Validation loss at step 6020: 0.01037839\n",
      "\n",
      "Batch loss at step 6040: 0.01078045\n",
      "Validation loss at step 6040: 0.01031616\n",
      "\n",
      "Batch loss at step 6060: 0.00992213\n",
      "Validation loss at step 6060: 0.01025457\n",
      "\n",
      "Batch loss at step 6080: 0.00940748\n",
      "Validation loss at step 6080: 0.01019338\n",
      "\n",
      "Batch loss at step 6100: 0.00941471\n",
      "Validation loss at step 6100: 0.01013256\n",
      "\n",
      "Batch loss at step 6120: 0.00975211\n",
      "Validation loss at step 6120: 0.01007210\n",
      "\n",
      "Batch loss at step 6140: 0.00983135\n",
      "Validation loss at step 6140: 0.01001175\n",
      "\n",
      "Batch loss at step 6160: 0.00988522\n",
      "Validation loss at step 6160: 0.00995206\n",
      "\n",
      "Batch loss at step 6180: 0.00981728\n",
      "Validation loss at step 6180: 0.00989278\n",
      "\n",
      "Batch loss at step 6200: 0.00943849\n",
      "Validation loss at step 6200: 0.00983385\n",
      "\n",
      "Batch loss at step 6220: 0.01021389\n",
      "Validation loss at step 6220: 0.00977491\n",
      "\n",
      "Batch loss at step 6240: 0.00940815\n",
      "Validation loss at step 6240: 0.00971657\n",
      "\n",
      "Batch loss at step 6260: 0.00890369\n",
      "Validation loss at step 6260: 0.00965860\n",
      "\n",
      "Batch loss at step 6280: 0.00891300\n",
      "Validation loss at step 6280: 0.00960098\n",
      "\n",
      "Batch loss at step 6300: 0.00923408\n",
      "Validation loss at step 6300: 0.00954372\n",
      "\n",
      "Batch loss at step 6320: 0.00931314\n",
      "Validation loss at step 6320: 0.00948653\n",
      "\n",
      "Batch loss at step 6340: 0.00936509\n",
      "Validation loss at step 6340: 0.00942993\n",
      "\n",
      "Batch loss at step 6360: 0.00930112\n",
      "Validation loss at step 6360: 0.00937371\n",
      "\n",
      "Batch loss at step 6380: 0.00893889\n",
      "Validation loss at step 6380: 0.00931787\n",
      "\n",
      "Batch loss at step 6400: 0.00967767\n",
      "Validation loss at step 6400: 0.00926209\n",
      "\n",
      "Batch loss at step 6420: 0.00892137\n",
      "Validation loss at step 6420: 0.00920690\n",
      "\n",
      "Batch loss at step 6440: 0.00842628\n",
      "Validation loss at step 6440: 0.00915208\n",
      "\n",
      "Batch loss at step 6460: 0.00843871\n",
      "Validation loss at step 6460: 0.00909759\n",
      "\n",
      "Batch loss at step 6480: 0.00874446\n",
      "Validation loss at step 6480: 0.00904339\n",
      "\n",
      "Batch loss at step 6500: 0.00882218\n",
      "Validation loss at step 6500: 0.00898930\n",
      "\n",
      "Batch loss at step 6520: 0.00887208\n",
      "Validation loss at step 6520: 0.00893576\n",
      "\n",
      "Batch loss at step 6540: 0.00881247\n",
      "Validation loss at step 6540: 0.00888258\n",
      "\n",
      "Batch loss at step 6560: 0.00846549\n",
      "Validation loss at step 6560: 0.00882979\n",
      "\n",
      "Batch loss at step 6580: 0.00917015\n",
      "Validation loss at step 6580: 0.00877699\n",
      "\n",
      "Batch loss at step 6600: 0.00846017\n",
      "Validation loss at step 6600: 0.00872472\n",
      "\n",
      "Batch loss at step 6620: 0.00797470\n",
      "Validation loss at step 6620: 0.00867278\n",
      "\n",
      "Batch loss at step 6640: 0.00798966\n",
      "Validation loss at step 6640: 0.00862116\n",
      "\n",
      "Batch loss at step 6660: 0.00828084\n",
      "Validation loss at step 6660: 0.00856981\n",
      "\n",
      "Batch loss at step 6680: 0.00835713\n",
      "Validation loss at step 6680: 0.00851855\n",
      "\n",
      "Batch loss at step 6700: 0.00840476\n",
      "Validation loss at step 6700: 0.00846780\n",
      "\n",
      "Batch loss at step 6720: 0.00834977\n",
      "Validation loss at step 6720: 0.00841738\n",
      "\n",
      "Batch loss at step 6740: 0.00801698\n",
      "Validation loss at step 6740: 0.00836737\n",
      "\n",
      "Batch loss at step 6760: 0.00868889\n",
      "Validation loss at step 6760: 0.00831739\n",
      "\n",
      "Batch loss at step 6780: 0.00802302\n",
      "Validation loss at step 6780: 0.00826792\n",
      "\n",
      "Batch loss at step 6800: 0.00754711\n",
      "Validation loss at step 6800: 0.00821873\n",
      "\n",
      "Batch loss at step 6820: 0.00756447\n",
      "Validation loss at step 6820: 0.00816988\n",
      "\n",
      "Batch loss at step 6840: 0.00784168\n",
      "Validation loss at step 6840: 0.00812128\n",
      "\n",
      "Batch loss at step 6860: 0.00791719\n",
      "Validation loss at step 6860: 0.00807279\n",
      "\n",
      "Batch loss at step 6880: 0.00796232\n",
      "Validation loss at step 6880: 0.00802481\n",
      "\n",
      "Batch loss at step 6900: 0.00791198\n",
      "Validation loss at step 6900: 0.00797715\n",
      "\n",
      "Batch loss at step 6920: 0.00759257\n",
      "Validation loss at step 6920: 0.00792983\n",
      "\n",
      "Batch loss at step 6940: 0.00823307\n",
      "Validation loss at step 6940: 0.00788253\n",
      "\n",
      "Batch loss at step 6960: 0.00760946\n",
      "Validation loss at step 6960: 0.00783573\n",
      "\n",
      "Batch loss at step 6980: 0.00714259\n",
      "Validation loss at step 6980: 0.00778923\n",
      "\n",
      "Batch loss at step 7000: 0.00716240\n",
      "Validation loss at step 7000: 0.00774301\n",
      "\n",
      "Batch loss at step 7020: 0.00742630\n",
      "Validation loss at step 7020: 0.00769703\n",
      "\n",
      "Batch loss at step 7040: 0.00750158\n",
      "Validation loss at step 7040: 0.00765116\n",
      "\n",
      "Batch loss at step 7060: 0.00754360\n",
      "Validation loss at step 7060: 0.00760578\n",
      "\n",
      "Batch loss at step 7080: 0.00749890\n",
      "Validation loss at step 7080: 0.00756067\n",
      "\n",
      "Batch loss at step 7100: 0.00719149\n",
      "Validation loss at step 7100: 0.00751590\n",
      "\n",
      "Batch loss at step 7120: 0.00780200\n",
      "Validation loss at step 7120: 0.00747111\n",
      "\n",
      "Batch loss at step 7140: 0.00721806\n",
      "Validation loss at step 7140: 0.00742679\n",
      "\n",
      "Batch loss at step 7160: 0.00675996\n",
      "Validation loss at step 7160: 0.00738279\n",
      "\n",
      "Batch loss at step 7180: 0.00678222\n",
      "Validation loss at step 7180: 0.00733905\n",
      "\n",
      "Batch loss at step 7200: 0.00703367\n",
      "Validation loss at step 7200: 0.00729552\n",
      "\n",
      "Batch loss at step 7220: 0.00710832\n",
      "Validation loss at step 7220: 0.00725206\n",
      "\n",
      "Batch loss at step 7240: 0.00714735\n",
      "Validation loss at step 7240: 0.00720906\n",
      "\n",
      "Batch loss at step 7260: 0.00710803\n",
      "Validation loss at step 7260: 0.00716644\n",
      "\n",
      "Batch loss at step 7280: 0.00681195\n",
      "Validation loss at step 7280: 0.00712411\n",
      "\n",
      "Batch loss at step 7300: 0.00739480\n",
      "Validation loss at step 7300: 0.00708181\n",
      "\n",
      "Batch loss at step 7320: 0.00684808\n",
      "Validation loss at step 7320: 0.00703992\n",
      "\n",
      "Batch loss at step 7340: 0.00639819\n",
      "Validation loss at step 7340: 0.00699830\n",
      "\n",
      "Batch loss at step 7360: 0.00642299\n",
      "Validation loss at step 7360: 0.00695698\n",
      "\n",
      "Batch loss at step 7380: 0.00666323\n",
      "Validation loss at step 7380: 0.00691590\n",
      "\n",
      "Batch loss at step 7400: 0.00673719\n",
      "Validation loss at step 7400: 0.00687487\n",
      "\n",
      "Batch loss at step 7420: 0.00677307\n",
      "Validation loss at step 7420: 0.00683425\n",
      "\n",
      "Batch loss at step 7440: 0.00673783\n",
      "Validation loss at step 7440: 0.00679392\n",
      "\n",
      "Batch loss at step 7460: 0.00645338\n",
      "Validation loss at step 7460: 0.00675388\n",
      "\n",
      "Batch loss at step 7480: 0.00701024\n",
      "Validation loss at step 7480: 0.00671385\n",
      "\n",
      "Batch loss at step 7500: 0.00649841\n",
      "Validation loss at step 7500: 0.00667416\n",
      "\n",
      "Batch loss at step 7520: 0.00605593\n",
      "Validation loss at step 7520: 0.00663469\n",
      "\n",
      "Batch loss at step 7540: 0.00608404\n",
      "Validation loss at step 7540: 0.00659550\n",
      "\n",
      "Batch loss at step 7560: 0.00631254\n",
      "Validation loss at step 7560: 0.00655653\n",
      "\n",
      "Batch loss at step 7580: 0.00638551\n",
      "Validation loss at step 7580: 0.00651765\n",
      "\n",
      "Batch loss at step 7600: 0.00641877\n",
      "Validation loss at step 7600: 0.00647913\n",
      "\n",
      "Batch loss at step 7620: 0.00638654\n",
      "Validation loss at step 7620: 0.00644094\n",
      "\n",
      "Batch loss at step 7640: 0.00611423\n",
      "Validation loss at step 7640: 0.00640304\n",
      "\n",
      "Batch loss at step 7660: 0.00664545\n",
      "Validation loss at step 7660: 0.00636517\n",
      "\n",
      "Batch loss at step 7680: 0.00616675\n",
      "Validation loss at step 7680: 0.00632770\n",
      "\n",
      "Batch loss at step 7700: 0.00573161\n",
      "Validation loss at step 7700: 0.00629048\n",
      "\n",
      "Batch loss at step 7720: 0.00576341\n",
      "Validation loss at step 7720: 0.00625349\n",
      "\n",
      "Batch loss at step 7740: 0.00598100\n",
      "Validation loss at step 7740: 0.00621669\n",
      "\n",
      "Batch loss at step 7760: 0.00605297\n",
      "Validation loss at step 7760: 0.00617998\n",
      "\n",
      "Batch loss at step 7780: 0.00608380\n",
      "Validation loss at step 7780: 0.00614361\n",
      "\n",
      "Batch loss at step 7800: 0.00605473\n",
      "Validation loss at step 7800: 0.00610749\n",
      "\n",
      "Batch loss at step 7820: 0.00579419\n",
      "Validation loss at step 7820: 0.00607166\n",
      "\n",
      "Batch loss at step 7840: 0.00630107\n",
      "Validation loss at step 7840: 0.00603585\n",
      "\n",
      "Batch loss at step 7860: 0.00585324\n",
      "Validation loss at step 7860: 0.00600037\n",
      "\n",
      "Batch loss at step 7880: 0.00542530\n",
      "Validation loss at step 7880: 0.00596513\n",
      "\n",
      "Batch loss at step 7900: 0.00546054\n",
      "Validation loss at step 7900: 0.00593008\n",
      "\n",
      "Batch loss at step 7920: 0.00566805\n",
      "Validation loss at step 7920: 0.00589526\n",
      "\n",
      "Batch loss at step 7940: 0.00573821\n",
      "Validation loss at step 7940: 0.00586044\n",
      "\n",
      "Batch loss at step 7960: 0.00576675\n",
      "Validation loss at step 7960: 0.00582603\n",
      "\n",
      "Batch loss at step 7980: 0.00574020\n",
      "Validation loss at step 7980: 0.00579188\n",
      "\n",
      "Batch loss at step 8000: 0.00549158\n",
      "Validation loss at step 8000: 0.00575802\n",
      "\n",
      "Batch loss at step 8020: 0.00597519\n",
      "Validation loss at step 8020: 0.00572418\n",
      "\n",
      "Batch loss at step 8040: 0.00555671\n",
      "Validation loss at step 8040: 0.00569069\n",
      "\n",
      "Batch loss at step 8060: 0.00513550\n",
      "Validation loss at step 8060: 0.00565739\n",
      "\n",
      "Batch loss at step 8080: 0.00517498\n",
      "Validation loss at step 8080: 0.00562435\n",
      "\n",
      "Batch loss at step 8100: 0.00537221\n",
      "Validation loss at step 8100: 0.00559150\n",
      "\n",
      "Batch loss at step 8120: 0.00544056\n",
      "Validation loss at step 8120: 0.00555870\n",
      "\n",
      "Batch loss at step 8140: 0.00546718\n",
      "Validation loss at step 8140: 0.00552626\n",
      "\n",
      "Batch loss at step 8160: 0.00544319\n",
      "Validation loss at step 8160: 0.00549405\n",
      "\n",
      "Batch loss at step 8180: 0.00520608\n",
      "Validation loss at step 8180: 0.00546210\n",
      "\n",
      "Batch loss at step 8200: 0.00566755\n",
      "Validation loss at step 8200: 0.00543015\n",
      "\n",
      "Batch loss at step 8220: 0.00527645\n",
      "Validation loss at step 8220: 0.00539852\n",
      "\n",
      "Batch loss at step 8240: 0.00486238\n",
      "Validation loss at step 8240: 0.00536710\n",
      "\n",
      "Batch loss at step 8260: 0.00490589\n",
      "Validation loss at step 8260: 0.00533589\n",
      "\n",
      "Batch loss at step 8280: 0.00509324\n",
      "Validation loss at step 8280: 0.00530487\n",
      "\n",
      "Batch loss at step 8300: 0.00515945\n",
      "Validation loss at step 8300: 0.00527386\n",
      "\n",
      "Batch loss at step 8320: 0.00518430\n",
      "Validation loss at step 8320: 0.00524318\n",
      "\n",
      "Batch loss at step 8340: 0.00516277\n",
      "Validation loss at step 8340: 0.00521272\n",
      "\n",
      "Batch loss at step 8360: 0.00493664\n",
      "Validation loss at step 8360: 0.00518253\n",
      "\n",
      "Batch loss at step 8380: 0.00537746\n",
      "Validation loss at step 8380: 0.00515229\n",
      "\n",
      "Batch loss at step 8400: 0.00501143\n",
      "Validation loss at step 8400: 0.00512236\n",
      "\n",
      "Batch loss at step 8420: 0.00460469\n",
      "Validation loss at step 8420: 0.00509262\n",
      "\n",
      "Batch loss at step 8440: 0.00465229\n",
      "Validation loss at step 8440: 0.00506309\n",
      "\n",
      "Batch loss at step 8460: 0.00482978\n",
      "Validation loss at step 8460: 0.00503375\n",
      "\n",
      "Batch loss at step 8480: 0.00489354\n",
      "Validation loss at step 8480: 0.00500444\n",
      "\n",
      "Batch loss at step 8500: 0.00491711\n",
      "Validation loss at step 8500: 0.00497543\n",
      "\n",
      "Batch loss at step 8520: 0.00489700\n",
      "Validation loss at step 8520: 0.00494664\n",
      "\n",
      "Batch loss at step 8540: 0.00468178\n",
      "Validation loss at step 8540: 0.00491810\n",
      "\n",
      "Batch loss at step 8560: 0.00510270\n",
      "Validation loss at step 8560: 0.00488954\n",
      "\n",
      "Batch loss at step 8580: 0.00476090\n",
      "Validation loss at step 8580: 0.00486127\n",
      "\n",
      "Batch loss at step 8600: 0.00436144\n",
      "Validation loss at step 8600: 0.00483317\n",
      "\n",
      "Batch loss at step 8620: 0.00441271\n",
      "Validation loss at step 8620: 0.00480524\n",
      "\n",
      "Batch loss at step 8640: 0.00458020\n",
      "Validation loss at step 8640: 0.00477747\n",
      "\n",
      "Batch loss at step 8660: 0.00464227\n",
      "Validation loss at step 8660: 0.00474976\n",
      "\n",
      "Batch loss at step 8680: 0.00466436\n",
      "Validation loss at step 8680: 0.00472232\n",
      "\n",
      "Batch loss at step 8700: 0.00464577\n",
      "Validation loss at step 8700: 0.00469511\n",
      "\n",
      "Batch loss at step 8720: 0.00444046\n",
      "Validation loss at step 8720: 0.00466812\n",
      "\n",
      "Batch loss at step 8740: 0.00484250\n",
      "Validation loss at step 8740: 0.00464114\n",
      "\n",
      "Batch loss at step 8760: 0.00452351\n",
      "Validation loss at step 8760: 0.00461442\n",
      "\n",
      "Batch loss at step 8780: 0.00413121\n",
      "Validation loss at step 8780: 0.00458794\n",
      "\n",
      "Batch loss at step 8800: 0.00418618\n",
      "Validation loss at step 8800: 0.00456162\n",
      "\n",
      "Batch loss at step 8820: 0.00434409\n",
      "Validation loss at step 8820: 0.00453544\n",
      "\n",
      "Batch loss at step 8840: 0.00440492\n",
      "Validation loss at step 8840: 0.00450931\n",
      "\n",
      "Batch loss at step 8860: 0.00442547\n",
      "Validation loss at step 8860: 0.00448344\n",
      "\n",
      "Batch loss at step 8880: 0.00440827\n",
      "Validation loss at step 8880: 0.00445778\n",
      "\n",
      "Batch loss at step 8900: 0.00421271\n",
      "Validation loss at step 8900: 0.00443234\n",
      "\n",
      "Batch loss at step 8920: 0.00459721\n",
      "Validation loss at step 8920: 0.00440691\n",
      "\n",
      "Batch loss at step 8940: 0.00429928\n",
      "Validation loss at step 8940: 0.00438172\n",
      "\n",
      "Batch loss at step 8960: 0.00391405\n",
      "Validation loss at step 8960: 0.00435670\n",
      "\n",
      "Batch loss at step 8980: 0.00397260\n",
      "Validation loss at step 8980: 0.00433187\n",
      "\n",
      "Batch loss at step 9000: 0.00412101\n",
      "Validation loss at step 9000: 0.00430720\n",
      "\n",
      "Batch loss at step 9020: 0.00418116\n",
      "Validation loss at step 9020: 0.00428256\n",
      "\n",
      "Batch loss at step 9040: 0.00419983\n",
      "Validation loss at step 9040: 0.00425816\n",
      "\n",
      "Batch loss at step 9060: 0.00418409\n",
      "Validation loss at step 9060: 0.00423394\n",
      "\n",
      "Batch loss at step 9080: 0.00399802\n",
      "Validation loss at step 9080: 0.00420992\n",
      "\n",
      "Batch loss at step 9100: 0.00436542\n",
      "Validation loss at step 9100: 0.00418588\n",
      "\n",
      "Batch loss at step 9120: 0.00408724\n",
      "Validation loss at step 9120: 0.00416209\n",
      "\n",
      "Batch loss at step 9140: 0.00370900\n",
      "Validation loss at step 9140: 0.00413843\n",
      "\n",
      "Batch loss at step 9160: 0.00377066\n",
      "Validation loss at step 9160: 0.00411494\n",
      "\n",
      "Batch loss at step 9180: 0.00391005\n",
      "Validation loss at step 9180: 0.00409160\n",
      "\n",
      "Batch loss at step 9200: 0.00396948\n",
      "Validation loss at step 9200: 0.00406830\n",
      "\n",
      "Batch loss at step 9220: 0.00398623\n",
      "Validation loss at step 9220: 0.00404525\n",
      "\n",
      "Batch loss at step 9240: 0.00397270\n",
      "Validation loss at step 9240: 0.00402243\n",
      "\n",
      "Batch loss at step 9260: 0.00379519\n",
      "Validation loss at step 9260: 0.00399980\n",
      "\n",
      "Batch loss at step 9280: 0.00414634\n",
      "Validation loss at step 9280: 0.00397714\n",
      "\n",
      "Batch loss at step 9300: 0.00388675\n",
      "Validation loss at step 9300: 0.00395468\n",
      "\n",
      "Batch loss at step 9320: 0.00351589\n",
      "Validation loss at step 9320: 0.00393241\n",
      "\n",
      "Batch loss at step 9340: 0.00358044\n",
      "Validation loss at step 9340: 0.00391028\n",
      "\n",
      "Batch loss at step 9360: 0.00371116\n",
      "Validation loss at step 9360: 0.00388826\n",
      "\n",
      "Batch loss at step 9380: 0.00376973\n",
      "Validation loss at step 9380: 0.00386628\n",
      "\n",
      "Batch loss at step 9400: 0.00378476\n",
      "Validation loss at step 9400: 0.00384450\n",
      "\n",
      "Batch loss at step 9420: 0.00377286\n",
      "Validation loss at step 9420: 0.00382293\n",
      "\n",
      "Batch loss at step 9440: 0.00360385\n",
      "Validation loss at step 9440: 0.00380154\n",
      "\n",
      "Batch loss at step 9460: 0.00393939\n",
      "Validation loss at step 9460: 0.00378011\n",
      "\n",
      "Batch loss at step 9480: 0.00369710\n",
      "Validation loss at step 9480: 0.00375892\n",
      "\n",
      "Batch loss at step 9500: 0.00333366\n",
      "Validation loss at step 9500: 0.00373789\n",
      "\n",
      "Batch loss at step 9520: 0.00340086\n",
      "Validation loss at step 9520: 0.00371698\n",
      "\n",
      "Batch loss at step 9540: 0.00352308\n",
      "Validation loss at step 9540: 0.00369620\n",
      "\n",
      "Batch loss at step 9560: 0.00358118\n",
      "Validation loss at step 9560: 0.00367545\n",
      "\n",
      "Batch loss at step 9580: 0.00359427\n",
      "Validation loss at step 9580: 0.00365491\n",
      "\n",
      "Batch loss at step 9600: 0.00358368\n",
      "Validation loss at step 9600: 0.00363454\n",
      "\n",
      "Batch loss at step 9620: 0.00342318\n",
      "Validation loss at step 9620: 0.00361432\n",
      "\n",
      "Batch loss at step 9640: 0.00374436\n",
      "Validation loss at step 9640: 0.00359411\n",
      "\n",
      "Batch loss at step 9660: 0.00351808\n",
      "Validation loss at step 9660: 0.00357411\n",
      "\n",
      "Batch loss at step 9680: 0.00316203\n",
      "Validation loss at step 9680: 0.00355425\n",
      "\n",
      "Batch loss at step 9700: 0.00323168\n",
      "Validation loss at step 9700: 0.00353455\n",
      "\n",
      "Batch loss at step 9720: 0.00334557\n",
      "Validation loss at step 9720: 0.00351498\n",
      "\n",
      "Batch loss at step 9740: 0.00340363\n",
      "Validation loss at step 9740: 0.00349540\n",
      "\n",
      "Batch loss at step 9760: 0.00341472\n",
      "Validation loss at step 9760: 0.00347600\n",
      "\n",
      "Batch loss at step 9780: 0.00340517\n",
      "Validation loss at step 9780: 0.00345674\n",
      "\n",
      "Batch loss at step 9800: 0.00325301\n",
      "Validation loss at step 9800: 0.00343766\n",
      "\n",
      "Batch loss at step 9820: 0.00356049\n",
      "Validation loss at step 9820: 0.00341855\n",
      "\n",
      "Batch loss at step 9840: 0.00334930\n",
      "Validation loss at step 9840: 0.00339963\n",
      "\n",
      "Batch loss at step 9860: 0.00300046\n",
      "Validation loss at step 9860: 0.00338084\n",
      "\n",
      "Batch loss at step 9880: 0.00307220\n",
      "Validation loss at step 9880: 0.00336218\n",
      "\n",
      "Batch loss at step 9900: 0.00317786\n",
      "Validation loss at step 9900: 0.00334364\n",
      "\n",
      "Batch loss at step 9920: 0.00323577\n",
      "Validation loss at step 9920: 0.00332514\n",
      "\n",
      "Batch loss at step 9940: 0.00324479\n",
      "Validation loss at step 9940: 0.00330681\n",
      "\n",
      "Batch loss at step 9960: 0.00323627\n",
      "Validation loss at step 9960: 0.00328862\n",
      "\n",
      "Batch loss at step 9980: 0.00309233\n",
      "Validation loss at step 9980: 0.00327060\n",
      "\n",
      "Test loss: 0.00307543\n"
     ]
    }
   ],
   "source": [
    "### Cell 3 ###\n",
    "### Run and evaluate ###\n",
    "\n",
    "num_steps = 10000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    for step in range(num_steps):\n",
    "        # Training data are randomized.\n",
    "        offset = (step * batch_size) % (train_y.shape[0] - batch_size)\n",
    "        batch_data = train_x[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_y[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 20 == 0):\n",
    "            print(\"Batch loss at step %d: %.8f\" % (step, l))\n",
    "            print(\"Validation loss at step %d: %.8f\\n\" % (step, ((sum((valid_prediction.eval() - valid_y) ** 2)) / valid_size / 2.)))\n",
    "    print(\"Test loss: %.8f\" % (sum((test_prediction.eval() - test_y) ** 2) / test_size / 2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
